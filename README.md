# Predicting Shelter Dog Outcomes

Please visit my blog post to read a formatted version of this post with visualizations - https://medium.com/@michaelkroog/predicting-shelter-dog-outcomes-db014269004f

 ## Project Goals:
Predict 3 outcome classes (Adopted, Euthanized, Returned to Owner)\
Find the strongest contributing factors to the Adoption outcome class\
Organize shelter data and create dashboards

 ### Looking For A Problem To Solve
The main reason why I chose to explore this problem is because of my two adopted shelter dogs. I visited many shelters looking for the right dog that would fit my lifestyle. Every person/family has their own reasons for why they adopt dogs, but I believe one of their reasons is common to my own — they are looking for the right dog to fit their lifestyle. It took some time, but I did find the perfect dogs. Each dog has its own story and unfortunately sometimes these stories make it difficult for a dog to find a home. During my adoption search I saw many dogs that may have had difficulties in finding a home (some dogs have too much energy, are too large or maybe the saddest reason — are too old or sick).
I know from experience that the dog a person sees in a shelter is not necessarily who that dog actually is. Shelters are a highly stressful environment for dogs. When a dog leaves a shelter and has the security of a home and a family that cares about them, they tend to change (often for the better). Giving a dog a chance to find a home the main reason why I wanted to use Data Science tools to help shelters prioritize their adoption efforts to maximize their adoptions. Specifically, by determining which dogs were more likely to be adopted by finding markers for adoption or strong contributing factors to the adopted class, I was able to discern which dogs were less likely to be adopted and measures that can be taken to increase their chances of adoption. Put another way, I thought that if a shelter knew why a dog was adoptable then it could spend more time and resources on dogs that typically have difficulties in finding a home. For example, I found that old dogs have a lower likelihood of being adopted and therefore, a shelter could allocate more of its resources on marketing the older dogs.

 ## The Data

 ### Class Imbalance
I found datasets from three different shelters that I cleaned and compiled into one dataframe. I yielded over 100,000 records, but only five variables that were common to all three shelters. The cleaned data also had a slight class imbalance with a ratio of approximately 4:3:3 for the Adopted, Euthanized and Returned to Owner classes. With the class imbalance being so slight I decided against resampling or SMOTE since it might introduce some bias into the models (discussed in more detail below) and instead, I chose the F1 scoring metric as a way to get more insight into the models’ performance. In addition, I used multiple algorithms to baseline as a way of seeing which algorithms would work best given the slight class imbalance.

 ## Modeling

 ### Baseline Scores
I started baseline modeling with Naive Bayes, Logistic Regression and Random Forest. Although I knew some of these algorithms weren’t ideal for a Multiclass Classification problem, it was still a great way to learn how and why they didn't produce great results. I cross validated with all models, but the results weren’t great. Naive Bayes resulted in an F1 Score of 0.37, Logistic Regressions resulted in a score of 0.56 and Random Forest resulted in a score 0.65. I didn’t believe that Naive Bayes or Logistic Regression were the right algorithms for this problem. While Random Forest would probably score higher with parameter tuning, I decided to focus on using XGBoost because it most likely would provide a higher-scoring model. I also tried feature engineering on the data to increase the number of features and spent time finding additional data on the relevant features that I could use to help train the model based on my experience of being a dog owner of two rescue dogs. Specifically, I focused on features that seemed to factor into adopters’ decisions to adopt dogs — weight or size, breed popularity, age at outcome and breed group. I used Beautiful Soup and Selenium to scrape data containing all of this information and was able to increase the features of the data from five to 22. After scraping the data, I trained the XGBoost model on the updated data set, which included the engineered features, and I was able to get a baseline F1 score of 0.82 with XGBoost.

 ### Tuning and Analysis
XGBoost allowed me to plot out feature importance and the results were interesting. Only a few of the features were largely responsible for the construction of the trees within the model, while many of the features had low importance.

XGBoost’s built in feature importance scores revealed some interesting if not peculiar results. The highest score according to ‘gain’ was the binary feature ‘Sterilized’. According to the data a dogs spayed or neutered status was recored at the time of the outcome. I found it odd that the highest scoring feature was ‘Sterilized’ because I believe many shelters have a policy of sterilizing dogs before adoption. But for dogs that are going to be euthanized, it wouldn’t make sense to sterilize them first. If there was a very high percentage of one outcome type and one of the binary results of the feature then this signal may skew the model. I found that this was the case. Over 97% of adopted dogs were sterilized and over 76% of euthanized dogs were not. The model captured the signal in this feature and thinks that sterilization is a strong predictor for the outcome class. For these reasons I decided to retrain the model without this feature.
After the ‘Sterilized’ feature removed and I tuned the model and it yielded an F1 Score of 0.96. The strongest contributing factor was now dog breed, with American Pit Bull Terrier being the strongest type of breed. Since dog breed inherently contains size, weight and group type — all of which are individual features in the data set — it makes sense that this would have a high feature importance. I decided to drop dog breed as a feature and retrain the model in order to see how each individual feature affected the outcome of the model. If some of these features have a low importance score I could drop them and reduce the complexity of the model.
XGBoost’s feature importance method was helpful and I reduced the number of features from 22 down to nine without changing the F1 Score. However I was still curious on how each feature effected the models prediction of each class, in a positive or negative way. Even though it wasn’t listed as the most important, I wanted to take a closer look at ‘Age at Outcome’, because I thought it would be helpful to understand how age and in what way it effected the model’s output.

I used PDPBox to generate a Partial Density Plot of ‘Age at Outcome’ for two classes Adopted and Euthanized (class 0 and class 1 respectively).

I found it interesting to look at the feature like this even though the results were a little unsurprising. The plot on the left shows that for Adopted dogs the feature has a little positive influence on the models output with peak strength at 0.16 years or about two months and starts to decline and turn negative after seven years. The plot on the right shows age for Euthanized dogs is mostly negative until around seven years where it starts to turn positive. From a practical standpoint this makes sense as younger dogs especially puppies are valued and therefore more likely to be adopted, while dogs that are older and possibly sick are more likely to be euthanized.

 ### Practical Application
During my search for shelter data I came across an organization called Shelter Animals Count (https://www.shelteranimalscount.org). Their mission statement is noble, they are looking to collect data from shelters across the county and to maintain an accurate database of animal counts and outcomes. I recommend looking at their website to get the full picture of their goals.

If their idea could be taken a step further by standardizing intake data (a wide range of specific data that can be used to make predictions) collected on dogs across shelters and this data was shared to one database, this would make predicting outcomes and finding markers for adoption easier. Shelters could also make recommendations to potential adopters on where to find the right type of dog. I would like to say that I have never worked in a shelter and therefore I don’t know to what extent data is standardized or how data is shared amongst shelters, but theoretically this seems like a good idea. The video below shows a Tableau dashboard of a hypothetical shelter dog database and the ability to select different characteristics to find a potential adopter and adoptee match.

Tableau Dashboard Video — https://vimeo.com/348496815a
